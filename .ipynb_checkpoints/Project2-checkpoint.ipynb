{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from torchmetrics.functional import retrieval_normalized_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "time_size = 10\n",
    "embed_dim = 128\n",
    "embed_max = 256\n",
    "label_num = 527\n",
    "top_label_num = 10\n",
    "bs = 16  # batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(data_names, top_label_num=top_label_num, embed_dim=embed_dim, embed_max=embed_max, label_num=label_num):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_names (list[str]): list of dataset versions to use\n",
    "        top_label_num (int, optional): Number of most frequent labels to use. Defaults to 10.\n",
    "        embed_dim (int, optional): Embedding dimension per second. Defaults to 128.\n",
    "        embed_max (int, optional): Maximum Possible value in the embedding vectors. Defaults to 256.\n",
    "        label_num (int, optional): Total number of distinct labels in dataset. Defaults to 527.\n",
    "\n",
    "    Returns:\n",
    "        tuple(normalized_embedding_tensor, label_tensor): tuple of embedding tensor after normalization, and the 527-dim label tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concat dataframes corresponding to the data_names\n",
    "    df = pd.DataFrame([])\n",
    "    for data_name in data_names:\n",
    "        add_df = pd.read_parquet(f'{data_name}.parquet')\n",
    "        add_df = add_df[~add_df.isnull()]\n",
    "        print(f\"{data_name}_df shape: \",add_df.shape)\n",
    "        add_df = add_df[add_df['audio_embedding'].apply(lambda x: len(x)) == time_size]\n",
    "        df = pd.concat([df,add_df],axis=0)\n",
    "        del add_df\n",
    "\n",
    "    def label_converter(x):\n",
    "        output = np.zeros(label_num,dtype=int)\n",
    "        for label in x:\n",
    "            output[label] = 1\n",
    "        return output\n",
    "    # Until here, same code as in the tfrecord_to_df function\n",
    "\n",
    "    # Convert \"labels\" column of df into np array\n",
    "    label_df = pd.DataFrame(np.vstack(df['labels'].apply(lambda x: label_converter(x))).reshape(-1,label_num))\n",
    "    top_label_idx = list(label_df.sum(axis=0).nlargest(top_label_num).index)  # Top 10 most frequent labels\n",
    "    label_df = label_df[top_label_idx]  # Only use top10 label data \n",
    "    label_df = label_df[label_df.sum(axis=1)>0]  # Drop audio data that does not contain any of top 10 label data\n",
    "    label_tensor = torch.Tensor(label_df.to_numpy())  # Obtain pytorch tensor\n",
    "    print(f\"Total label shape: \",label_tensor.size())\n",
    "\n",
    "    # Drop audio data that does not contain any of top 10 label data\n",
    "    df['label'] = df['label'].apply(lambda x: x[top_label_idx])\n",
    "    df = df[df['label'].apply(lambda x: sum(x))>0]\n",
    "\n",
    "    # Convert \"audio embedding\" column of df into np array and torch tensor\n",
    "    embeddings = np.vstack(df['audio_embedding'].apply(lambda x: np.vstack(x))).reshape(-1,time_size,embed_dim)\n",
    "    embedding_tensor = torch.Tensor(embeddings)\n",
    "    print(f\"Total embedding shape: \", embedding_tensor.size())\n",
    "    \n",
    "    assert embedding_tensor.shape[0] == label_tensor.shape[0], \"Feature and label dim does not coincide!\"\n",
    "    \n",
    "    return embedding_tensor/embed_max, label_tensor   # normalize embedding_tensor by its maximum possible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal_train_df shape:  (21782, 5)\n",
      "eval_df shape:  (19976, 5)\n",
      "Total label shape:  torch.Size([22582, 10])\n",
      "Total embedding shape:  torch.Size([22582, 10, 128])\n",
      "Train data Size: 18064 , Val data Size: 2258,Test data Size : 2260\n"
     ]
    }
   ],
   "source": [
    "# Used bal_train and eval version of AudioSet data\n",
    "embedding_all, label_all = df_to_tensor(['bal_train','eval'], top_label_num)\n",
    "\n",
    "# Randomly splitting into train / validation / test data (8:1:1)\n",
    "permute_idx = np.random.permutation(np.arange(embedding_all.shape[0]))\n",
    "train_idx = permute_idx[:(permute_idx.shape[0]//5)*4]\n",
    "val_idx = permute_idx[(permute_idx.shape[0]//5)*4:(permute_idx.shape[0]//10)*9]\n",
    "test_idx = permute_idx[(permute_idx.shape[0]//10)*9:]\n",
    "print(f\"Train data Size: {len(train_idx)} , Val data Size: {len(val_idx)},Test data Size : {len(test_idx)}\")\n",
    "\n",
    "train_set = TensorDataset(embedding_all[train_idx], label_all[train_idx])\n",
    "val_set = TensorDataset(embedding_all[val_idx], label_all[val_idx])\n",
    "test_set = TensorDataset(embedding_all[test_idx], label_all[test_idx])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=bs, shuffle=True, num_workers=cpu_count)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=1, shuffle=False, num_workers=cpu_count)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=1, shuffle=False, num_workers=cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class YoutubeAudioClassifier(nn.Module):\n",
    "    def __init__(self, time_size=time_size, embed_dim=embed_dim, fc_dim=64, output_dim=top_label_num):\n",
    "        \"\"\"Consists of intra-temporal CNN blocks and inter-temporal CNN blocks, followed by 1 FC layer.\n",
    "\n",
    "        Args:\n",
    "            time_size (int, optional): Time horizon per each audio data. Defaults to 10.\n",
    "            embed_dim (int, optional): Embedding dimension per second. Defaults to 128.\n",
    "            fc_dim (int, optional): Dimension of final fully connected layer. Defaults to 64.\n",
    "            output_dim (int, optional): Output dimension of the model. Defaults to 10.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(YoutubeAudioClassifier, self).__init__()\n",
    "        self.time_size = time_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embed_dim1, self.embed_dim2 = self.split_embed_dim()\n",
    "        self.fc_dim = fc_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        \n",
    "        ### For each layers, input and output dimensions are specified in the comment.\n",
    "        \n",
    "        # Level1 intra-temporal CNN block\n",
    "        self.intra_init_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.time_size, self.time_size//2, 3, padding=1),    # 10*16*8 -> 5*16*8\n",
    "            nn.BatchNorm2d(self.time_size//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Three Level2 intra-temporal CNN blocks\n",
    "        self.intra_stride = nn.Sequential(\n",
    "            nn.Conv2d(self.time_size//2, self.time_size//4, 2, stride=2),  # 5*16*8 -> 2*8*4\n",
    "            nn.BatchNorm2d(self.time_size//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.intra_dim1_dil = nn.Sequential(\n",
    "            nn.Conv2d(self.time_size//2, self.time_size//2, 3, dilation=(2,1)),  # 5*16*8 -> 5*12*6\n",
    "            nn.BatchNorm2d(self.time_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.time_size//2, self.time_size//4, 3, dilation=(2,1)),  # 5*12*6 -> 2*8*4\n",
    "            nn.BatchNorm2d(self.time_size//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.intra_dim2_dil = nn.Sequential(\n",
    "            nn.Conv2d(self.time_size//2, self.time_size//4, (2,3), dilation=(1,2), stride=(2,1)),  # 5*16*8 -> 2*8*4\n",
    "            nn.BatchNorm2d(self.time_size//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Two Level1 inter-termporal CNN blocks\n",
    "        self.inter_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, (3,5), stride=(1,2)),  # 1*10*128 -> 4*8*62\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, (3,8), dilation=(1,3)),  # 4*8*62 -> 8*6*41\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.inter_max_conv = nn.Sequential(\n",
    "            nn.MaxPool2d((2,6), stride=(2,3), padding=(1,0)),  # 1*10*128 -> 1*6*41\n",
    "            nn.Conv2d(1, 8, 3, padding=1), # 1*6*41 -> 8*6*41\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Level2 inter-temporal CNN block\n",
    "        self.inter_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 4, (3,3), stride=(1,2)),  # 8*6*41 -> 4*4*20\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, (3,5), dilation=(1,3), padding=(1,0)),  # 4*4*20 -> 2*4*8\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Concatenating two CNN blocks and normalize\n",
    "        self.combine_norm = nn.Sequential(\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.fc_dim, self.output_dim)  # 64 -> 10\n",
    "\n",
    "\n",
    "    \n",
    "    # For balanced Width * Height split of input data for intra blocks    \n",
    "    def split_embed_dim(self):\n",
    "        for i in reversed(np.arange(np.ceil(np.sqrt(self.embed_dim))+1)):\n",
    "            if self.embed_dim % i == 0:\n",
    "                return self.embed_dim // int(i) , int(i)\n",
    "                break\n",
    "            \n",
    "    \n",
    "    def forward(self, data):\n",
    "        intra_data = data.view(-1, self.time_size, self.embed_dim1, self.embed_dim2)  # Input Data for intra-temporal CNN block\n",
    "        inter_data = data.view(-1, 1, self.time_size, self.embed_dim)  # Input data for inter-temporal CNN block\n",
    "        \n",
    "        intra_block1_out = self.intra_init_conv(intra_data)\n",
    "        # Concatenate three intra_block2 components\n",
    "        intra_block2_out = self.intra_stride(intra_block1_out) + self.intra_dim1_dil(intra_block1_out) + self.intra_dim2_dil(intra_block1_out)\n",
    "        \n",
    "        # Concatenate two inter_block1 components\n",
    "        inter_block1_out = self.inter_conv1(inter_data) + self.inter_max_conv(inter_data)\n",
    "        inter_block2_out = self.inter_conv2(inter_block1_out).transpose(-2,-1)\n",
    "        \n",
    "        # Concatenate output of intra and inter temporal blocks, and normalize\n",
    "        cnn_out = self.combine_norm(intra_block2_out + inter_block2_out).view(-1,self.fc_dim)\n",
    "        \n",
    "        # Final fully connected layer\n",
    "        fc_out = self.fc(cnn_out)\n",
    "        \n",
    "        return F.softmax(fc_out,dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch_lightning configuration \n",
    "class YoutubeAudioClassifierLight(pl.LightningModule):\n",
    "    def __init__(self, model, train_loss_type, valid_metric_type, test_metric_type):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (nn.Module): Pytorch-implemened model.\n",
    "            train_loss_type (string): Type of loss function used for training. \"msml\" or \"CE\" are allowed.\n",
    "            valid_metric_type (string): Type of metric used while validation. \"ndcg\" or \"Precision@k\" are allowed.\n",
    "            test_metric_type (string): Type of metric used while testing. \"ndcg\" or \"Precision@k\" are allowed.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.train_lossF = self.define_loss(train_loss_type)\n",
    "        self.valid_lossF = self.define_loss(valid_metric_type)\n",
    "        self.test_lossF = self.define_loss(test_metric_type)\n",
    "    \n",
    "    \n",
    "    # Defining loss (or metric) function for given parameter\n",
    "    def define_loss(self, loss_type, Precision_k=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            loss_type (string): \"msml\" or \"CE\" are allowed for training, and \"ndcg\" or \"Precision@k\" are allowed for validation/testing.\n",
    "            Precision_k (int, optional): Number of topk used for Precision@k metric. Defaults to 1.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: For \"msml\", if reduction_type parameter is not valid\n",
    "            ValueError: If loss_type parameter is not among \"msml\",\"ce\",\"ndcg\",\"Precision@k\".\n",
    "\n",
    "        Returns:\n",
    "           function: Loss / Metric function to be used, corresponding to loss_type parameter.\n",
    "        \"\"\"\n",
    "        if loss_type == 'msml':\n",
    "            if device == torch.device(\"mps\"):\n",
    "                # In MPS device, F.logsigmoid is not supported.\n",
    "                # It is well-known that softplus(beta = -1) is identical to logsigmoid.\n",
    "                def multilabel_soft_margin_loss(input, target, weight = None, size_average = None, reduce = None, reduction = \"mean\"):\n",
    "                    loss = -(target * F.softplus(input, beta = -1) + (1 - target) * F.softplus(-input, beta = -1)) \n",
    "\n",
    "                    if weight is not None:\n",
    "                        loss = loss * weight\n",
    "\n",
    "                    class_dim = input.dim() - 1\n",
    "                    C = input.size(class_dim)\n",
    "                    loss = loss.sum(dim=class_dim) / C  # only return N loss values\n",
    "\n",
    "                    if reduction == \"none\":\n",
    "                        ret = loss\n",
    "                    elif reduction == \"mean\":\n",
    "                        ret = loss.mean()\n",
    "                    elif reduction == \"sum\":\n",
    "                        ret = loss.sum()\n",
    "                    else:\n",
    "                        ret = input\n",
    "                        raise ValueError(reduction + \" is not valid\")\n",
    "                    return ret\n",
    "                return multilabel_soft_margin_loss\n",
    "            else:\n",
    "                return nn.MultiLabelSoftMarginLoss()\n",
    "        elif loss_type == 'ndcg':\n",
    "            return retrieval_normalized_dcg\n",
    "        elif loss_type == 'Precision@k':\n",
    "            def Precision_at_k(input, target):\n",
    "                topk_idx = torch.topk(input,Precision_k,dim=1).indices\n",
    "                return torch.stack([(target[i][topk_idx[i]]).float() for i in range(target.shape[0])]).mean()\n",
    "            return Precision_at_k\n",
    "        elif loss_type == 'CE':\n",
    "            # Since label data in AudioSet dataset is not one-hot encoded (b/c possibly multi-valued),\n",
    "            # Need to properly transform CrossEntropyLoss functon into specific form\n",
    "            def MultiCELoss(input, target):\n",
    "                loss = nn.CrossEntropyLoss()\n",
    "                nonzeros = target.nonzero()\n",
    "                idx = nonzeros[:,0]\n",
    "                label = nonzeros[:,1]\n",
    "                norm_input = input[idx] / torch.bincount(idx)[idx].view(-1,1)  # Normalize each inputdata in batch by its duplicate count\n",
    "                return loss(norm_input, label)\n",
    "            return MultiCELoss\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported Loss function\")\n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        embedding, labels = batch\n",
    "        train_loss = self.train_lossF(self.model(embedding), labels)\n",
    "        self.log(\"train_loss\", train_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return train_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        embedding, labels = batch\n",
    "        valid_loss = self.valid_lossF(self.model(embedding), labels)\n",
    "        self.log(\"validation_metric\", valid_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        embedding, labels = batch\n",
    "        test_loss = self.test_lossF(self.model(embedding), labels)\n",
    "        self.log(\"test_metric\", test_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and the corresponding Pytorch_lightning object\n",
    "YACLight = YoutubeAudioClassifierLight(YoutubeAudioClassifier(), \"msml\",\"ndcg\",\"ndcg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"./lightning_logs\")\n",
    "n_epoch = 1000\n",
    "\n",
    "if device == torch.device(\"mps\"):\n",
    "    trainer = pl.Trainer(accelerator=\"mps\", logger=tb_logger, max_epochs=n_epoch)\n",
    "elif device == torch.device(\"cuda\"):\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", logger=tb_logger, max_epochs=n_epoch)\n",
    "else:\n",
    "    trainer = pl.Trainer(accelerator=\"cpu\", logger=tb_logger, max_epochs=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e88d63b48904e71b8c443d7631e3019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_metric_epoch       0.41614019870758057\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_metric_epoch': 0.41614019870758057}]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline metric (Before Training)\n",
    "trainer.test(model=YACLight, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type                     | Params\n",
      "---------------------------------------------------------\n",
      "0 | model       | YoutubeAudioClassifier   | 3.0 K \n",
      "1 | train_lossF | MultiLabelSoftMarginLoss | 0     \n",
      "---------------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bf1f5ab68c48cb9513136a55e53dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=YACLight, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df463037d700419e81e2cfe6ca5370f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_metric_epoch       0.9122195839881897\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_metric_epoch': 0.9122195839881897}]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Result (After training)\n",
    "trainer.test(model=YACLight, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
